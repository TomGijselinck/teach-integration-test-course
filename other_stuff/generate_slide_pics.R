require(MASS)

# REGRESSION
sim <- data.frame(mvrnorm(n = 20, c(10,10), matrix(c(4, 3.6, 3.6, 4), ncol = 2, byrow=TRUE)))
plot(X2 ~ X1, data = sim, pch = 16, col = "red", cex = 1.5)
lm_sim <- lm(X2 ~ X1, data = sim)
abline(lm_sim$coefficients, lwd = 5)
points(lm_sim$fitted.values ~ X1, data = sim, cex = 1.5)
lines(lm_sim$fitted.values ~ X1, data = sim, col = "blue")
with(sim, segments(X1, X2, X1, lm_sim$fitted.values, lwd = 3))
dev.copy(pdf,'regr_rmse.pdf')
dev.off()

# CLUSTERING
set.seed(1)
sim1 <- data.frame(mvrnorm(n = 100, c(2.5,0), matrix(c(1, 0, 0, 1), ncol = 2, byrow=TRUE)))
distm1 <- as.matrix(dist(sim1))
maxind1 <- which(distm1 == max(distm1), arr.ind = TRUE)
mean1 <- apply(sim1, 2, mean)
sim2 <- data.frame(mvrnorm(n = 100, c(5,5), matrix(c(1, 0, 0, 1), ncol = 2, byrow=TRUE)))
distm2 <- as.matrix(dist(sim2))
maxind2 <- which(distm2 == max(distm2), arr.ind = TRUE)
mean2 <- apply(sim2, 2, mean)
sim3 <- data.frame(mvrnorm(n = 100, c(0,5), matrix(c(1, 0, 0, 1), ncol = 2, byrow=TRUE)))
distm3 <- as.matrix(dist(sim3))
maxind3 <- which(distm3 == max(distm3), arr.ind = TRUE)
mean3 <- apply(sim3, 2, mean)
plot(X2 ~ X1, data = sim1, pch = 16, col = "lightblue", cex = 1, xlim = c(-5,10), ylim = c(-5,10))
points(mean1[1], mean1[2], pch = 22, bg = "darkblue", col = "black", cex = 2)
points(X2 ~ X1, data = sim2, pch = 16, col = "pink", cex = 1)
points(mean2[1], mean2[2], pch = 22, bg = "darkred", col = "black", cex = 2)
points(X2 ~ X1, data = sim3, pch = 16, col = "lightgreen", cex = 1)
points(mean3[1], mean3[2], pch = 22, bg = "darkgreen", col = "black", cex = 2)
dev.copy(pdf,'clust_centr.pdf')
dev.off()
#segments(sim1[maxind1[1,1],1], sim1[maxind1[1,1],2], sim1[maxind1[1,2],1], sim1[maxind1[1,2],2], lwd = 2, col = "blue")
#segments(sim2[maxind2[1,1],1], sim2[maxind2[1,1],2], sim2[maxind2[1,2],1], sim2[maxind2[1,2],2], lwd = 2, col = "red")
segments(sim3[maxind3[1,1],1], sim3[maxind3[1,1],2], sim3[maxind3[1,2],1], sim3[maxind3[1,2],2], lwd = 2, col = "green")
#dev.copy(pdf,'clust_diam.pdf')
#dev.off()
#segments(mean1[1], mean1[2], mean2[1], mean2[2], lwd = 2)
#segments(mean1[1], mean1[2], mean3[1], mean3[2], lwd = 2)
segments(mean2[1], mean2[2], mean3[1], mean3[2], lwd = 2)
dev.copy(pdf,'clust_dunn.pdf')
dev.off()

# BIAS & VARIANCE
set.seed(1)
library(polynom)
x <- -10+runif(10)*20
y <- x^2+rnorm(length(x))*10
lm_pol <- lm(y ~ poly(x, 9, raw=TRUE))
lm_pol2 <- lm(y ~ poly(x, 2, raw = TRUE))
lm_pol3 <- lm(y ~ x)
p <- polynomial(lm_pol$coefficients)
p2 <- polynomial(lm_pol2$coefficients)
y <- y[order(x)]
x <- sort(x)
plot(x[1:10],y[1:10], xlim = c(-11,11), ylim = c(-600,600), cex = 1.5, pch = 16, col="red")
dev.copy(png,'points.png')
dev.off()
lines(p2, lwd = 2, col = "green")
dev.copy(png,'real.png')
dev.off()
abline(lm_pol3$coefficients, lwd = 2, col = "blue")
dev.copy(png,'bias.png')
dev.off()
lines(p, lwd = 2, col = "magenta")
dev.copy(png,'variance.png')
dev.off()

# K-NEAREST NEIGHBORS
set.seed(1)
sim1 <- data.frame(mvrnorm(n = 10, c(2.5,0), matrix(c(1, 0, 0, 1), ncol = 2, byrow=TRUE)))
sim2 <- data.frame(mvrnorm(n = 10, c(0,0), matrix(c(1, 0, 0, 1), ncol = 2, byrow=TRUE)))
plot(sim1, xlim=c(-3,5.5), ylim=c(-3,3), col="red", pch=16, cex = 1.5)
points(sim2, col="blue", pch=16, cex=1.5)
dev.copy(pdf,'knn_training.pdf')
dev.off()
points(1.3,-2, col="darkgray", pch=15, cex=2)
dev.copy(pdf,'knn_new_observation.pdf')
dev.off()
segments(x0=rep(1.3, 10),y0=rep(-2, 10),x1 = sim1[,1], y1=sim1[,2], lwd = 2, col="darkgray")
segments(x0=rep(1.3, 10),y0=rep(-2, 10),x1 = sim2[,1], y1=sim2[,2], lwd = 2, col="darkgray")
dev.copy(pdf,'knn_distances.pdf')
dev.off()
segments(x0=1.3, y0=-2, x1=sim2[4,1], y1=sim2[4,2], lwd=3, col="blue")
points(1.3,-2, col="blue", pch=15, cex=2)
dev.copy(pdf,'knn_shortest.pdf')
dev.off()

# VORONOI
library(deldir)
x <- c(0.43949186, 0.77532814, 0.11782475, 0.35801559, 0.71666908, 0.93637376, 0.93787087, 0.26948754, 0.21281674, 0.50090499, 0.04047676, 0.93225458, 0.48290936, 0.98852486, 0.61118461, 0.85696836, 0.63806236, 0.53096559, 0.58995806, 0.89755494)
y <- c(0.13004635, 0.40886464, 0.91230276, 0.52809828, 0.25648163, 0.72429901, 0.28103747, 0.07085646, 0.04868199, 0.70123639, 0.88836284, 0.36454012, 0.89607151, 0.91200372, 0.77136399, 0.25200289, 0.24101831, 0.85472437, 0.25192760, 0.02320495)
z <- deldir(x,y,rw=c(0,1,0,1))
w <- tile.list(z)
cols <- rep(c("red","blue"), 10)
plot(w, fillcol = cols, close = TRUE)
points(x, y, cex=1.5, pch = 16, col=rep(c("pink","darkblue")))
dev.copy(pdf,'knn_voronoi.pdf')
dev.off()

# LOGISTIC REGRESSION
curve(logit, xlab="p", ylab="logit(p)")
dev.copy(pdf,'logr_logit.pdf')
dev.off()
curve(inv.logit, xlab="logit(p)", ylab="p", xlim=c(-4,4))
dev.copy(pdf,'logr_logistic.pdf')
dev.off()
set.seed(1)
age <- runif(20,0,90) 
age <- sort(age) 
survive <- c(0,0,0,0,0,1,0,0,1,0,1,1,1,1,1,0,1,1,1,1) 
data <- as.data.frame(cbind(age,survive)) 
plot(age,survive,xlab="age",ylab="deceased") 
dev.copy(pdf,'logr_example_input.pdf')
dev.off()
logr <- glm(survive~age,family=binomial,data)
curve(predict(logr,data.frame(age=x),type="resp"),add=TRUE)
points(age,fitted(logr),pch=20) 
dev.copy(pdf,'logr_example_fit.pdf')
dev.off()

# ROC CURVE
income <- read.csv(url('http://s3.amazonaws.com/assets.datacamp.com/course/intro_to_ml/income.csv'))
set.seed(1)
shuffled <- income[sample(nrow(income)),]
rm(income)
train <- shuffled[1:round(0.7*nrow(shuffled)),]
test <- shuffled[(round(0.7*nrow(shuffled))+1):nrow(shuffled),]
rm(shuffled)
logr <- glm(income ~ ., train, family = binomial(logit))
rm(train)
prob <- predict(logr, test, type = "response")
library(ROCR)
pred <- prediction(prob, test$income)
perf <- performance(pred, "tpr", "fpr")
auc <- performance(pred, "auc")
plot(perf, col="darkgreen", lwd=5)
dev.copy(pdf,'ROC_example.pdf')
dev.off()